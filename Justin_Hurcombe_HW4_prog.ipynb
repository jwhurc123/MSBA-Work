{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0979a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import PySpark and read input file as a DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1434b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sparkSession instance\n",
    "spark = SparkSession.builder.appName(\"HW4\").getOrCreate()\n",
    "\n",
    "# remove INFO logging from executing spark-session job on terminal\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "input_path = r\"C:\\Users\\Justin_Hurcombe.PF164PM6\\MSIS2427-BigData\\whitehouse_waves-2016_12.csv\" # input csv file\n",
    "\n",
    "\n",
    "\n",
    "# create df from input path\n",
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(input_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16bc9c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all column headers to lowercase\n",
    "for col in df.columns:\n",
    "    df = df.withColumnRenamed(col,col.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25bef2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temporary view of df1 to execute SQL query\n",
    "df.createOrReplaceTempView(\"df1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d480ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL query to create df2, where all missing namelast ans visitee_namelast values are removed\n",
    "df2 = spark.sql(\"SELECT * FROM df1 WHERE (namelast IS NOT NULL AND visitee_namelast IS NOT NULL)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea379e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create visitor and visitee columns in df2 DataFrame following the (lastname, firstname) format\n",
    "\n",
    "\n",
    "# import necessary packages\n",
    "from pyspark.sql.functions import lower, concat, lit\n",
    "\n",
    "\n",
    "# add the concatenated columns to df2\n",
    "df2 = df2.withColumn('visitor', concat(lower(df.namelast),lit(', '),lower(df.namefirst)))\n",
    "\n",
    "df2 = df2.withColumn('visitee',concat(lower(df.visitee_namelast),lit(', '),lower(df.visitee_namefirst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c4a9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Frequent Visitors\n",
      "+-----------------+-----+\n",
      "|          visitor|count|\n",
      "+-----------------+-----+\n",
      "|  kidwell, lauren|  222|\n",
      "| thomas, benjamin|  196|\n",
      "|     haro, steven|  183|\n",
      "|berner, katherine|  177|\n",
      "|   grant, patrick|  155|\n",
      "|     haas, jordan|  152|\n",
      "|    garza, steven|  127|\n",
      "|  martin, kathryn|  122|\n",
      "|     cohen, mandy|  122|\n",
      "|  brown, jennifer|  117|\n",
      "+-----------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### group visitors (names are lower case) by frequency, and then show the top 10 most frequent visitors\n",
    "\n",
    "# create dataframe to group visitors by count, and then order the results descending\n",
    "visitor_count = df2.groupBy('visitor').count().orderBy(\"count\",ascending=False)\n",
    "\n",
    "# show top 10 rows of visitor dataframe \n",
    "print(\"Top 10 Most Frequent Visitors\")\n",
    "visitor_count.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98fcccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Most Frequent Visitees\n",
      "+--------------------+------+\n",
      "|             visitee| count|\n",
      "+--------------------+------+\n",
      "|    office, visitors|430881|\n",
      "|waves, visitorsof...| 44129|\n",
      "|        bryant, ruth| 13970|\n",
      "|       oneil, olivia| 13155|\n",
      "|     thompson, jared| 11618|\n",
      "|            /, potus| 10900|\n",
      "|      burton, collin|  9672|\n",
      "|      megan, matthew|  7944|\n",
      "|     mayerson, asher|  6886|\n",
      "| dessources, kalisha|  5289|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### group visitees (names are lower case) by frequency, and then show the top 10 most frequently visited people\n",
    "\n",
    "# create dataframe to group visitees by count, and then order the results descending\n",
    "visitee_count = df2.groupBy('visitee').count().orderBy(\"count\",ascending=False)\n",
    "\n",
    "# show top 10 rows of visitee dataframe \n",
    "print(\"Top 10 Most Frequent Visitees\")\n",
    "visitee_count.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b182893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------+-----+\n",
      "|          visitor|        visitee|count|\n",
      "+-----------------+---------------+-----+\n",
      "|  kidwell, lauren| yudelson, alex|  103|\n",
      "|     haas, jordan| yudelson, alex|   90|\n",
      "|   grant, patrick| yudelson, alex|   89|\n",
      "| thomas, benjamin| yudelson, alex|   89|\n",
      "|     cohen, mandy|lambrew, jeanne|   84|\n",
      "|     haro, steven| yudelson, alex|   84|\n",
      "|berner, katherine| yudelson, alex|   82|\n",
      "|   roche, shannon| yudelson, alex|   70|\n",
      "| urizar, jennifer| johnson, katie|   68|\n",
      "|  martin, kathryn|lambrew, jeanne|   61|\n",
      "+-----------------+---------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### group visitor/visitee combos by frequency, and then show the top 10 most frequent visitor-visitee combo\n",
    "\n",
    "# create dataframe to group visitor/visitee combos by count, and then order the results descending\n",
    "visitor_visitee_count = df2.groupBy(['visitor','visitee']).count().orderBy(\"count\",ascending=False)\n",
    "\n",
    "# show top 10 rows of visitor/visitee combo dataframe\n",
    "visitor_visitee_count.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1024319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|Dropped_Records|\n",
      "+---------------+\n",
      "|          59255|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to show count of records dropped from table df1\n",
    "spark.sql(\"SELECT COUNT(*) AS Dropped_Records FROM df1 WHERE (namelast IS NULL OR visitee_namelast IS NULL)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d9a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de5047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
